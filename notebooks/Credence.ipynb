{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "088e8ecf",
   "metadata": {},
   "source": [
    "# Running Gift-Eval with Credence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324acc12",
   "metadata": {},
   "source": [
    "### Credence: Time‑Series Foundation Model\n",
    "\n",
    "> **Note:** Our model was previously named *Kairos‑1.0*; its successor, **Credence**, is now released publicly with an API for external evaluation.  \n",
    "> The rename also helps avoid confusion with other models that later adopted the Kairos name or other similar names.\n",
    "\n",
    "This notebook lets you replicate the **GIFT‑Eval** evaluation using the **Credence API**.  \n",
    "The model was internally tested and the official results are published on the GIFT‑Eval leaderboard.\n",
    "\n",
    "To run your own tests:\n",
    "1. Get an API key and follow setup instructions at [https://docs.credence.continualist.ai/docs](https://docs.credence.continualist.ai/docs).  \n",
    "2. Use this notebook to call the API and run evaluations.\n",
    "\n",
    "⚠️ Usage note:   \n",
    "By default, accounts include limited credits for evaluation due to associated compute costs, so more credits maybe needed for testing all GIFT-Eval datasets.  \n",
    "For reporting issues or extended testing, email **[team@continualist.ai](team@continualist.ai)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30d3c29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/geremiapompei/Desktop/Work/ContinualIST/gift-eval\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -andas (/opt/homebrew/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: requests in /opt/homebrew/lib/python3.10/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.10/site-packages (from requests) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.10/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.10/site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.10/site-packages (from requests) (2023.7.22)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -andas (/opt/homebrew/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/opt/homebrew/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install requests if not already installed\n",
    "%cd ..\n",
    "! pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82550f8",
   "metadata": {},
   "source": [
    "After obtaining your API key from the Credence dashboard at https://app.credence.continualist.ai, paste it below to authenticate your API requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0595fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"<YOUR_CREDENCE_API_KEY_HERE>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aabf2bf",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682aca15",
   "metadata": {},
   "source": [
    "Import the necessary third-party dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f28e43ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geremiapompei/Desktop/Work/ContinualIST/gift-eval/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from gift_eval.data import Dataset\n",
    "from gluonts.ev.metrics import (\n",
    "    MAE, MAPE, MASE, MSE, MSIS, ND, NRMSE, RMSE, SMAPE, MeanWeightedSumQuantileLoss,)\n",
    "from gluonts.model.forecast import QuantileForecast\n",
    "from gluonts.model import evaluate_model\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bfcb79",
   "metadata": {},
   "source": [
    "Prepare the configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f987838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path configurations\n",
    "out_dir = 'results/Credence'\n",
    "\n",
    "# Model\n",
    "model_name = \"Credence\"\n",
    "\n",
    "# Auxiliary configurations\n",
    "seed = 0\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18a02f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment configurations\n",
    "short_datasets = \"m4_yearly m4_quarterly m4_monthly m4_weekly m4_daily m4_hourly electricity/15T electricity/H electricity/D electricity/W solar/10T solar/H solar/D solar/W hospital covid_deaths us_births/D us_births/M us_births/W saugeenday/D saugeenday/M saugeenday/W temperature_rain_with_missing kdd_cup_2018_with_missing/H kdd_cup_2018_with_missing/D car_parts_with_missing restaurant hierarchical_sales/D hierarchical_sales/W LOOP_SEATTLE/5T LOOP_SEATTLE/H LOOP_SEATTLE/D SZ_TAXI/15T SZ_TAXI/H M_DENSE/H M_DENSE/D ett1/15T ett1/H ett1/D ett1/W ett2/15T ett2/H ett2/D ett2/W jena_weather/10T jena_weather/H jena_weather/D bitbrains_fast_storage/5T bitbrains_fast_storage/H bitbrains_rnd/5T bitbrains_rnd/H bizitobs_application bizitobs_service bizitobs_l2c/5T bizitobs_l2c/H\"\n",
    "med_long_datasets = \"electricity/15T electricity/H solar/10T solar/H kdd_cup_2018_with_missing/H LOOP_SEATTLE/5T LOOP_SEATTLE/H SZ_TAXI/15T M_DENSE/H ett1/15T ett1/H ett2/15T ett2/H jena_weather/10T jena_weather/H bitbrains_fast_storage/5T bitbrains_rnd/5T bizitobs_application bizitobs_service bizitobs_l2c/5T bizitobs_l2c/H\"\n",
    "dataset_properties = 'notebooks/dataset_properties.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c29637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "class CredenceAPI:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        api_key: str,\n",
    "        horizon: int,\n",
    "        frequency: str = \"H\",\n",
    "    ):\n",
    "        self.api_key = api_key\n",
    "        self.horizon = horizon\n",
    "        self.frequency = frequency\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        test_data,\n",
    "        **kwargs\n",
    "    ):\n",
    "        preds = []\n",
    "        for batch in test_data:\n",
    "            quantiles = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "            context_input = []\n",
    "            prev_value = 0\n",
    "            for value in batch[\"target\"].tolist():\n",
    "                context_input.append(prev_value)\n",
    "                prev_value = value if not np.isnan(value) else prev_value\n",
    "            response = requests.post(\n",
    "                \"https://api.credence.continualist.ai/api/v1/credence/forecast\",\n",
    "                json={\n",
    "                    \"frequency\": self.frequency,\n",
    "                    \"horizon\": self.horizon,\n",
    "                    \"model_type\": \"large\",\n",
    "                    \"quantiles\": quantiles,\n",
    "                    \"sequence\": [\n",
    "                        {\n",
    "                            \"timestamp\": (batch[\"start\"] + i).strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "                            \"target\": v\n",
    "                        }\n",
    "                        for i, v in enumerate(context_input)\n",
    "                    ]\n",
    "                },\n",
    "                headers={\n",
    "                    \"Content-Type\": \"application/json\",\n",
    "                    \"x-api-key\": self.api_key\n",
    "                }\n",
    "            )\n",
    "            if response.status_code != 200:\n",
    "                raise ValueError(f\"Error: {response.text}\")\n",
    "            response = response.json()\n",
    "            forecast_arrays = np.array([\n",
    "                response[\"quantiles\"][str(q)]\n",
    "                for q in quantiles\n",
    "            ])\n",
    "\n",
    "            # Uncomment to see remaining credits\n",
    "            # print(f\"Remaining credits: {response['remaining_credits']}/{response['total_credits']} ({response['remaining_credits'] / response['total_credits'] * 100:.2f}%)\")\n",
    "\n",
    "            # pred has shape: batch, forecast_len, quantiles\n",
    "            preds.append(\n",
    "                QuantileForecast(\n",
    "                    forecast_arrays=forecast_arrays,\n",
    "                    forecast_keys=[str(q) for q in quantiles],\n",
    "                    start_date=batch[\"start\"] + len(context_input),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e9a469",
   "metadata": {},
   "source": [
    "Experiment wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c4b0470",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_row = [\n",
    "    \"dataset\",\n",
    "    \"model\",\n",
    "    \"eval_metrics/MSE[mean]\",\n",
    "    \"eval_metrics/MSE[0.5]\",\n",
    "    \"eval_metrics/MAE[mean]\",\n",
    "    \"eval_metrics/MAE[0.5]\",\n",
    "    \"eval_metrics/MASE[0.5]\",\n",
    "    \"eval_metrics/MAPE[0.5]\",\n",
    "    \"eval_metrics/sMAPE[0.5]\",\n",
    "    \"eval_metrics/MSIS\",\n",
    "    \"eval_metrics/RMSE[mean]\",\n",
    "    \"eval_metrics/NRMSE[mean]\",\n",
    "    \"eval_metrics/ND[0.5]\",\n",
    "    \"eval_metrics/mean_weighted_sum_quantile_loss\",\n",
    "    \"domain\",\n",
    "    \"num_variates\"\n",
    "]\n",
    "\n",
    "\n",
    "def run_gift_eval(zs=False, save=False, verbose=True):\n",
    "    set_seed(seed)\n",
    "\n",
    "    # Get union of short and med_long datasets\n",
    "    all_datasets = sorted(\n",
    "        set(short_datasets.split() + med_long_datasets.split()))\n",
    "    all_datasets = reversed(all_datasets)\n",
    "\n",
    "    dataset_properties_map = json.load(open(dataset_properties))\n",
    "\n",
    "    # Instantiate the metrics\n",
    "    metrics = [\n",
    "        MSE(forecast_type=\"mean\"),\n",
    "        MSE(forecast_type=0.5),\n",
    "        MAE(forecast_type=\"mean\"),\n",
    "        MAE(forecast_type=0.5),\n",
    "        MASE(),\n",
    "        MAPE(),\n",
    "        SMAPE(),\n",
    "        MSIS(),\n",
    "        RMSE(),\n",
    "        NRMSE(),\n",
    "        ND(),\n",
    "        MeanWeightedSumQuantileLoss(\n",
    "            quantile_levels=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n",
    "    ]\n",
    "\n",
    "    # ## Evaluation\n",
    "    # Define the path for the CSV file\n",
    "    csv_file_path = os.path.join(out_dir, \"all_results.csv\")\n",
    "\n",
    "    pretty_names = {\n",
    "        \"saugeenday\": \"saugeen\",\n",
    "        \"temperature_rain_with_missing\": \"temperature_rain\",\n",
    "        \"kdd_cup_2018_with_missing\": \"kdd_cup_2018\",\n",
    "        \"car_parts_with_missing\": \"car_parts\",\n",
    "    }\n",
    "\n",
    "    if not os.path.exists(csv_file_path) and save:\n",
    "        with open(csv_file_path, \"a\", newline=\"\") as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "\n",
    "            # Write the header\n",
    "            writer.writerow(base_row)\n",
    "    if save:\n",
    "        df_res_done = pd.read_csv(csv_file_path)\n",
    "        done_datasets = df_res_done[\"dataset\"].values\n",
    "    else:\n",
    "        done_datasets = []\n",
    "    df_res = pd.DataFrame(columns=base_row)\n",
    "\n",
    "    # the zero-shot subset whithout data leakage for the chronos pretraining corpus (to fairly compare with tirex and chronos models)\n",
    "    if zs:\n",
    "        excluded = [\"solar/H\", \"m4_monthly\", \"m4_weekly\", \"m4_daily\", \"m4_hourly\", \"electricity/15T\", \"electricity/H\",\n",
    "                    \"electricity/W\", \"kdd_cup_2018_with_missing/D\", \"kdd_cup_2018_with_missing/H\", \"temperature_rain_with_missing\"]\n",
    "    else:\n",
    "        excluded = []\n",
    "\n",
    "    for ds_name in all_datasets:\n",
    "        if ds_name in excluded:\n",
    "            continue\n",
    "        set_seed(seed)\n",
    "        terms = [\"short\", \"medium\", \"long\"]\n",
    "        for term in terms:\n",
    "            if (term == \"medium\" or term == \"long\") and ds_name not in med_long_datasets.split():\n",
    "                continue\n",
    "\n",
    "            if \"/\" in ds_name:\n",
    "                ds_key = ds_name.split(\"/\")[0]\n",
    "                ds_freq = ds_name.split(\"/\")[1]\n",
    "                ds_key = ds_key.lower()\n",
    "                ds_key = pretty_names.get(ds_key, ds_key)\n",
    "            else:\n",
    "                ds_key = ds_name.lower()\n",
    "                ds_key = pretty_names.get(ds_key, ds_key)\n",
    "                ds_freq = dataset_properties_map[ds_key][\"frequency\"]\n",
    "            ds_config = f\"{ds_key}/{ds_freq}/{term}\"\n",
    "\n",
    "            to_univariate = (\n",
    "                False\n",
    "                if Dataset(name=ds_name, term=term, to_univariate=False).target_dim == 1\n",
    "                else True\n",
    "            )\n",
    "            dataset = Dataset(name=ds_name, term=term,\n",
    "                              to_univariate=to_univariate)\n",
    "\n",
    "            all_lengths = []\n",
    "            for x in dataset.test_data:\n",
    "                if len(x[0][\"target\"].shape) == 1:\n",
    "                    all_lengths.append(len(x[0][\"target\"]))\n",
    "                else:\n",
    "                    all_lengths.append(x[0][\"target\"].shape[1])\n",
    "\n",
    "            if ds_config in done_datasets:\n",
    "                df_res = df_res._append(\n",
    "                    df_res_done.loc[df_res_done['dataset'] == ds_config], ignore_index=True)\n",
    "                continue\n",
    "\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"Dataset: {ds_name}, Freq = {dataset.freq}, H = {dataset.prediction_length}\")\n",
    "\n",
    "            # Evaluate\n",
    "            model = CredenceAPI(\n",
    "                api_key=API_KEY,\n",
    "                horizon=dataset.prediction_length,\n",
    "                frequency=dataset.freq,\n",
    "            )\n",
    "            res = evaluate_model(\n",
    "                model,\n",
    "                test_data=dataset.test_data,\n",
    "                metrics=metrics,\n",
    "                batch_size=batch_size,\n",
    "                axis=None,\n",
    "                mask_invalid_label=True,\n",
    "                allow_nan_forecast=False,\n",
    "            )\n",
    "            if verbose:\n",
    "                print(f'MASE: {res[\"MASE[0.5]\"][0]}')\n",
    "\n",
    "            # Append the results to the CSV file\n",
    "            row = [\n",
    "                ds_config,\n",
    "                model_name,\n",
    "                res[\"MSE[mean]\"][0],\n",
    "                res[\"MSE[0.5]\"][0],\n",
    "                res[\"MAE[mean]\"][0],\n",
    "                res[\"MAE[0.5]\"][0],\n",
    "                res[\"MASE[0.5]\"][0],\n",
    "                res[\"MAPE[0.5]\"][0],\n",
    "                res[\"sMAPE[0.5]\"][0],\n",
    "                res[\"MSIS\"][0],\n",
    "                res[\"RMSE[mean]\"][0],\n",
    "                res[\"NRMSE[mean]\"][0],\n",
    "                res[\"ND[0.5]\"][0],\n",
    "                res[\"mean_weighted_sum_quantile_loss\"][0],\n",
    "                dataset_properties_map[ds_key][\"domain\"],\n",
    "                dataset_properties_map[ds_key][\"num_variates\"],\n",
    "            ]\n",
    "            if save:\n",
    "                with open(csv_file_path, \"a\", newline=\"\") as csvfile:\n",
    "                    writer = csv.writer(csvfile)\n",
    "                    writer.writerow(row)\n",
    "                if verbose:\n",
    "                    print(\n",
    "                        f\"Results for {ds_name} have been written to {csv_file_path}\")\n",
    "            df_res.loc[len(df_res)] = row\n",
    "\n",
    "    # Print Results\n",
    "    seasonal_naive = pd.read_csv(\n",
    "        f\"results/seasonal_naive/all_results.csv\").sort_values('dataset')\n",
    "    dataset = seasonal_naive['dataset'].to_list()\n",
    "    seasonal_naive_mase = seasonal_naive[f'eval_metrics/MASE[0.5]'].to_numpy()\n",
    "    seasonal_naive_crps = seasonal_naive[f'eval_metrics/mean_weighted_sum_quantile_loss'].to_numpy()\n",
    "    df = df_res\n",
    "    df = df.sort_values(by=\"dataset\")\n",
    "    df['normalized MASE'] = np.zeros(len(df))\n",
    "    df['normalized CRPS'] = np.zeros(len(df))\n",
    "    df['freq'] = np.zeros(len(df))\n",
    "    df['len'] = np.zeros(len(df))\n",
    "    for ds in df['dataset']:\n",
    "        idx = dataset.index(ds)\n",
    "        _, f, l = ds.split('/')\n",
    "        df.loc[df['dataset'] == ds, 'freq'] = f\n",
    "        df.loc[df['dataset'] == ds, 'len'] = l\n",
    "        df.loc[df['dataset'] == ds, 'normalized MASE'] = df.loc[df['dataset']\n",
    "                                                                == ds, f'eval_metrics/MASE[0.5]'].values / seasonal_naive_mase[idx]\n",
    "        df.loc[df['dataset'] == ds, 'normalized CRPS'] = df.loc[df['dataset'] == ds,\n",
    "                                                                f'eval_metrics/mean_weighted_sum_quantile_loss'].values / seasonal_naive_crps[idx]\n",
    "\n",
    "    df = df.sort_values(by=['dataset'])\n",
    "\n",
    "    def geo_mean(iterable):\n",
    "        a = np.array(iterable)\n",
    "        return a.prod()**(1.0/len(a))\n",
    "\n",
    "    mase = geo_mean(df['normalized MASE'].to_numpy())\n",
    "    crps = geo_mean(df['normalized CRPS'].to_numpy())\n",
    "\n",
    "    return mase, crps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59132bc",
   "metadata": {},
   "source": [
    "Start the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f29951d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final GIFT-Eval Performance of Credence:\n",
      "MASE = 0.6901174782158342, CRPS = 0.4728288546556098\n"
     ]
    }
   ],
   "source": [
    "mase, crps = run_gift_eval(verbose=True, save=True)\n",
    "print(\n",
    "    f'Final GIFT-Eval Performance of {model_name}:\\nMASE = {mase}, CRPS = {crps}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gift-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
