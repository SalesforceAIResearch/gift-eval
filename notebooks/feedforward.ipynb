{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start: Running Feed Forward model on gift-eval benchmark\n",
    "\n",
    "This notebook shows how to run the Feed Forward model on the gift-eval benchmark.\n",
    "\n",
    "Make sure you download the gift-eval benchmark and set the `GIFT-EVAL` environment variable correctly before running this notebook.\n",
    "\n",
    "We will use the `Dataset` class to load the data and run the model. If you have not already please check out the [dataset.ipynb](./dataset.ipynb) notebook to learn more about the `Dataset` class. We are going to just run the model on two datasets for brevity. But feel free to run on any dataset by changing the `short_datasets` and `med_long_datasets` variables below.\n",
    "\n",
    "We will use the `SimpleFeedForwardEstimator` class from gluonts to run the Feed Forward model. It demonstrates how to use the `gluonts` estimator interface to train and evaluate a deep learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# short_datasets = \"m4_yearly m4_quarterly m4_monthly m4_weekly m4_daily m4_hourly electricity/15T electricity/H electricity/D electricity/W solar/10T solar/H solar/D solar/W hospital covid_deaths us_births/D us_births/M us_births/W saugeenday/D saugeenday/M saugeenday/W temperature_rain_with_missing kdd_cup_2018_with_missing/H kdd_cup_2018_with_missing/D car_parts_with_missing restaurant hierarchical_sales/D hierarchical_sales/W LOOP_SEATTLE/5T LOOP_SEATTLE/H LOOP_SEATTLE/D SZ_TAXI/15T SZ_TAXI/H M_DENSE/H M_DENSE/D ett1/15T ett1/H ett1/D ett1/W ett2/15T ett2/H ett2/D ett2/W jena_weather/10T jena_weather/H jena_weather/D bitbrains_fast_storage/5T bitbrains_fast_storage/H bitbrains_rnd/5T bitbrains_rnd/H bizitobs_application bizitobs_service bizitobs_l2c/5T bizitobs_l2c/H\"\n",
    "short_datasets = \"m4_weekly\"\n",
    "\n",
    "# med_long_datasets = \"electricity/15T electricity/H solar/10T solar/H kdd_cup_2018_with_missing/H LOOP_SEATTLE/5T LOOP_SEATTLE/H SZ_TAXI/15T M_DENSE/H ett1/15T ett1/H ett2/15T ett2/H jena_weather/10T jena_weather/H bitbrains_fast_storage/5T bitbrains_rnd/5T bizitobs_application bizitobs_service bizitobs_l2c/5T bizitobs_l2c/H\"\n",
    "med_long_datasets = \"bizitobs_l2c/H\"\n",
    "\n",
    "all_datasets = short_datasets.split() + med_long_datasets.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.ev.metrics import (\n",
    "    MSE,\n",
    "    MAE,\n",
    "    MASE,\n",
    "    MAPE,\n",
    "    SMAPE,\n",
    "    MSIS,\n",
    "    RMSE,\n",
    "    NRMSE,\n",
    "    ND,\n",
    "    MeanWeightedSumQuantileLoss,\n",
    ")\n",
    "\n",
    "# Instantiate the metrics\n",
    "metrics = [\n",
    "    MSE(forecast_type=\"mean\"),\n",
    "    MSE(forecast_type=0.5),\n",
    "    MAE(),\n",
    "    MASE(),\n",
    "    MAPE(),\n",
    "    SMAPE(),\n",
    "    MSIS(),\n",
    "    RMSE(),\n",
    "    NRMSE(),\n",
    "    ND(),\n",
    "    MeanWeightedSumQuantileLoss(quantile_levels=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation\n",
    "\n",
    "We will use the `evaluate_model` function to evaluate the model. This function is a helper function to evaluate the model on the test data and return the results in a dictionary. We are going to follow the naming conventions explained in the [README](../README.md) file to store the results in a csv file called `all_results.csv` under the `results/feedforward` folder.\n",
    "\n",
    "The first column in the csv file is the dataset config name which is a combination of the dataset name and the term. Since some datasets have frequency embedded in their names in order to keep the naming standard consistent we will use the following convention:\n",
    "```python\n",
    "if there is no frequency embedded in the dataset name:\n",
    "    f\"{dataset_name}/nan/{term}\"\n",
    "else:\n",
    "    f\"{dataset_name}/{freq}/{term}\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.model import evaluate_model\n",
    "from gluonts.torch.model.simple_feedforward import SimpleFeedForwardEstimator\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "from gluonts.time_feature import get_seasonality\n",
    "from gift_eval.data import Dataset\n",
    "from gluonts.evaluation import make_evaluation_predictions\n",
    "# Iterate over all available datasets\n",
    "\n",
    "output_dir = \"../results/feedforward\"\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define the path for the CSV file\n",
    "csv_file_path = os.path.join(output_dir, 'all_results.csv')\n",
    "\n",
    "with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    \n",
    "    # Write the header\n",
    "    writer.writerow(['dataset', 'model', 'runtime', 'eval_metrics/MSE[mean]', 'eval_metrics/MSE[0.5]', 'eval_metrics/MAE[0.5]', 'eval_metrics/MASE[0.5]', 'eval_metrics/MAPE[0.5]', 'eval_metrics/sMAPE[0.5]', 'eval_metrics/MSIS', 'eval_metrics/RMSE[mean]', 'eval_metrics/NRMSE[mean]', 'eval_metrics/ND[0.5]', 'eval_metrics/mean_weighted_sum_quantile_loss'])\n",
    "    \n",
    "for ds_name in all_datasets:\n",
    "    print(f\"Processing dataset: {ds_name}\")\n",
    "    terms = [\"short\", \"medium\", \"long\"]\n",
    "    for term in terms:\n",
    "        if (term == \"medium\" or term == \"long\") and ds_name not in med_long_datasets.split():\n",
    "            continue\n",
    "\n",
    "        # Initialize the dataset\n",
    "        to_univariate = False if Dataset(name=ds_name, term=term,to_univariate=False).target_dim == 1 else True\n",
    "        dataset = Dataset(name=ds_name, term=term, to_univariate=to_univariate)\n",
    "        season_length = get_seasonality(dataset.freq)\n",
    "        ds_config = f'{ds_name}/{term}' if '/' in ds_name else f'{ds_name}/nan/{term}'\n",
    "\n",
    "        estimator = SimpleFeedForwardEstimator(\n",
    "            prediction_length=dataset.prediction_length,\n",
    "            context_length=dataset.prediction_length,\n",
    "            trainer_kwargs=dict(\n",
    "                max_epochs=1,\n",
    "            )\n",
    "        )\n",
    "        predictor = estimator.train(dataset.validation_dataset)\n",
    "\n",
    "        # Measure the time taken for evaluation\n",
    "        tic = time.perf_counter()\n",
    "        res = evaluate_model(\n",
    "                predictor,\n",
    "                test_data=dataset.test_data,\n",
    "                metrics=metrics,\n",
    "                batch_size=512,\n",
    "                axis=None,\n",
    "                mask_invalid_label=True,\n",
    "                allow_nan_forecast=False,\n",
    "                seasonality=season_length,\n",
    "            )\n",
    "        toc = time.perf_counter()\n",
    "        runtime = str(toc - tic)\n",
    "\n",
    "        # Append the results to the CSV file\n",
    "        with open(csv_file_path, 'a', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow([\n",
    "                ds_config, 'feedforward', runtime,\n",
    "                res['MSE[mean]'][0], res['MSE[0.5]'][0], res['MAE[0.5]'][0],\n",
    "                res['MASE[0.5]'][0], res['MAPE[0.5]'][0], res['sMAPE[0.5]'][0],\n",
    "                res['MSIS'][0], res['RMSE[mean]'][0], res['NRMSE[mean]'][0],\n",
    "                res['ND[0.5]'][0], res['mean_weighted_sum_quantile_loss'][0]\n",
    "            ])\n",
    "\n",
    "        print(f\"Results for {ds_name} have been written to {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Running the above cell will generate a csv file called `all_results.csv` under the `results/feedforward` folder containing the results for the Feed Forward model on the gift-eval benchmark. The csv file will look like this:\n",
    "\n",
    "```csv\n",
    "dataset,model,runtime,eval_metrics/MSE[mean],eval_metrics/MSE[0.5],eval_metrics/MAE[0.5],eval_metrics/MASE[0.5],eval_metrics/MAPE[0.5],eval_metrics/sMAPE[0.5],eval_metrics/MSIS,eval_metrics/RMSE[mean],eval_metrics/NRMSE[mean],eval_metrics/ND[0.5],eval_metrics/mean_weighted_sum_quantile_loss\n",
    "m4_weekly/nan/short,naive,15.629891242999292,998187.4986072424,998187.4986072424,616.229697878723,8.713851129463317,0.13540839699368573,0.13435515801605688,305.2888195282654,999.0933382858892,0.18201932294743392,0.11226750103291235,0.15794989760333017\n",
    "bizitobs_l2c/H/short,naive,2.142069427998649,218.37996031746033,218.37996031746033,11.058859204489087,1.0732444657205147,1.1792454708108513,0.931732904343378,14.687091955741334,14.777684538433629,0.7965550429257633,0.5961008333498701,0.5223290347366207\n",
    "bizitobs_l2c/H/medium,naive,0.5844004099999438,95.65786830357143,95.65786830357143,6.411117699032738,0.6475043837754751,0.7025878809253328,0.8223082042875745,5.891396580554725,9.780484052620885,0.5922231650883761,0.3882029146050128,0.3191126908779432\n",
    "bizitobs_l2c/H/long,naive,0.6866592850019515,96.99658978174604,96.99658978174604,6.4524383060515875,0.6859682805474133,0.7790951384149116,0.8294547913566468,5.712622384804599,9.8486846726731,0.6015860848612848,0.3941335546174002,0.3221545731921662\n",
    "```\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bench_oss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
