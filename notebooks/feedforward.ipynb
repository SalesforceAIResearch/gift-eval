{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start: Running Feed Forward model on gift-eval benchmark\n",
    "\n",
    "This notebook shows how to run the Feed Forward model on the gift-eval benchmark.\n",
    "\n",
    "Make sure you download the gift-eval benchmark and set the `GIFT-EVAL` environment variable correctly before running this notebook.\n",
    "\n",
    "We will use the `Dataset` class to load the data and run the model. If you have not already please check out the [dataset.ipynb](./dataset.ipynb) notebook to learn more about the `Dataset` class. We are going to just run the model on two datasets for brevity. But feel free to run on any dataset by changing the `short_datasets` and `med_long_datasets` variables below.\n",
    "\n",
    "We will use the `SimpleFeedForwardEstimator` class from gluonts to run the Feed Forward model. It demonstrates how to use the `gluonts` estimator interface to train and evaluate a deep learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# short_datasets = \"m4_yearly m4_quarterly m4_monthly m4_weekly m4_daily m4_hourly electricity/15T electricity/H electricity/D electricity/W solar/10T solar/H solar/D solar/W hospital covid_deaths us_births/D us_births/M us_births/W saugeenday/D saugeenday/M saugeenday/W temperature_rain_with_missing kdd_cup_2018_with_missing/H kdd_cup_2018_with_missing/D car_parts_with_missing restaurant hierarchical_sales/D hierarchical_sales/W LOOP_SEATTLE/5T LOOP_SEATTLE/H LOOP_SEATTLE/D SZ_TAXI/15T SZ_TAXI/H M_DENSE/H M_DENSE/D ett1/15T ett1/H ett1/D ett1/W ett2/15T ett2/H ett2/D ett2/W jena_weather/10T jena_weather/H jena_weather/D bitbrains_fast_storage/5T bitbrains_fast_storage/H bitbrains_rnd/5T bitbrains_rnd/H bizitobs_application bizitobs_service bizitobs_l2c/5T bizitobs_l2c/H\"\n",
    "short_datasets = \"m4_weekly\"\n",
    "\n",
    "# med_long_datasets = \"electricity/15T electricity/H solar/10T solar/H kdd_cup_2018_with_missing/H LOOP_SEATTLE/5T LOOP_SEATTLE/H SZ_TAXI/15T M_DENSE/H ett1/15T ett1/H ett2/15T ett2/H jena_weather/10T jena_weather/H bitbrains_fast_storage/5T bitbrains_rnd/5T bizitobs_application bizitobs_service bizitobs_l2c/5T bizitobs_l2c/H\"\n",
    "med_long_datasets = \"bizitobs_l2c/H\"\n",
    "\n",
    "all_datasets = short_datasets.split() + med_long_datasets.split()\n",
    "\n",
    "dataset_properties_map = json.load(open('dataset_properties.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import re\n",
    "# import json\n",
    "\n",
    "# # read model properties from dataset_properties.csv\\n,\n",
    "# dataset_properties = pd.read_csv('dataset_properties.csv')\n",
    "# # Reforemat the the first element of each row after the header following these rules:\\n,\n",
    "# # 1. make all characters lowercase\\n,\n",
    "# dataset_properties['dataset'] = dataset_properties['dataset'].apply(lambda x: x.lower())\n",
    "# # 2. replace all spaces with underscores\\n,\n",
    "# dataset_properties['dataset'] = dataset_properties['dataset'].apply(lambda x: x.replace(' ', '_'))\n",
    "# # 3. Replace all dashes with underscores\\n,\n",
    "# dataset_properties['dataset'] = dataset_properties['dataset'].apply(lambda x: x.replace('-', '_'))\n",
    "# # 4. Replace consecutive underscores with a single underscore. There maybe more than 2 consecutive underscores\n",
    "# dataset_properties['dataset'] = dataset_properties['dataset'].apply(lambda x: re.sub('_+', '_', x))\n",
    "# # 5. Remove all leading and trailing underscores\n",
    "# dataset_properties['dataset'] = dataset_properties['dataset'].apply(lambda x: x.strip('_'))\n",
    "\n",
    "# # replace consecutive underscores with a single underscore\n",
    "\n",
    "# # dataset_properties['dataset'] = dataset_properties['dataset'].apply(lambda x: x.lower().replace(' ', '_'))\n",
    "# # convert it to a dictionary, with dataset as the key, and the value as another dictionary. The inner dictionary has the column names as the key, and the value as the value.\n",
    "# dataset_properties_dict = dataset_properties.set_index('dataset').T.to_dict('dict')\n",
    "# dataset_properties_dict.keys()\n",
    "# dataset_properties_dict[\"m4_weekly\"]\n",
    "\n",
    "# # Write the dataset_properties_dict to a json file\n",
    "# with open('dataset_properties.json', 'w') as f:\n",
    "#     json.dump(dataset_properties_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.ev.metrics import (\n",
    "    MSE,\n",
    "    MAE,\n",
    "    MASE,\n",
    "    MAPE,\n",
    "    SMAPE,\n",
    "    MSIS,\n",
    "    RMSE,\n",
    "    NRMSE,\n",
    "    ND,\n",
    "    MeanWeightedSumQuantileLoss,\n",
    ")\n",
    "\n",
    "# Instantiate the metrics\n",
    "metrics = [\n",
    "    MSE(forecast_type=\"mean\"),\n",
    "    MSE(forecast_type=0.5),\n",
    "    MAE(),\n",
    "    MASE(),\n",
    "    MAPE(),\n",
    "    SMAPE(),\n",
    "    MSIS(),\n",
    "    RMSE(),\n",
    "    NRMSE(),\n",
    "    ND(),\n",
    "    MeanWeightedSumQuantileLoss(quantile_levels=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation\n",
    "\n",
    "We will use the `evaluate_model` function to evaluate the model. This function is a helper function to evaluate the model on the test data and return the results in a dictionary. We are going to follow the naming conventions explained in the [README](../README.md) file to store the results in a csv file called `all_results.csv` under the `results/feedforward` folder.\n",
    "\n",
    "The first column in the csv file is the dataset config name which is a combination of the dataset name, frequency and the term:\n",
    "\n",
    "```python\n",
    "f\"{dataset_name}/{freq}/{term}\"\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/exp-series/miniconda3/envs/bench_oss/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/export/exp-series/miniconda3/envs/bench_oss/lib/python3.10/site-packages/lightning/pytorch/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: temperature_rain_with_missing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                   | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | model | SimpleFeedForwardModel | 13.3 K | train\n",
      "---------------------------------------------------------\n",
      "13.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "13.3 K    Total params\n",
      "0.053     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: |          | 50/? [00:01<00:00, 29.17it/s, v_num=6, train_loss=-1.44]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached -1.43507 (best -1.43507), saving model to '/export/exp-series/Projects/oss/gift-eval/notebooks/lightning_logs/version_6/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: |          | 50/? [00:01<00:00, 28.29it/s, v_num=6, train_loss=-1.44]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63488it [48:40, 21.85it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m predictor \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mtrain(dataset\u001b[38;5;241m.\u001b[39mvalidation_dataset)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Measure the time taken for evaluation\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_invalid_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan_forecast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseasonality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseason_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Append the results to the CSV file\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(csv_file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m csvfile:\n",
      "File \u001b[0;32m/export/exp-series/miniconda3/envs/bench_oss/lib/python3.10/site-packages/gluonts/model/evaluation.py:262\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, test_data, metrics, axis, batch_size, mask_invalid_label, allow_nan_forecast, seasonality)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03mEvaluate ``model`` when applied to ``test_data``, according to ``metrics``.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;124;03mReturn results as a Pandas ``DataFrame``.\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    260\u001b[0m forecasts \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_data\u001b[38;5;241m.\u001b[39minput)\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mevaluate_forecasts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforecasts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforecasts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask_invalid_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_invalid_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan_forecast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan_forecast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseasonality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseasonality\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/export/exp-series/miniconda3/envs/bench_oss/lib/python3.10/site-packages/gluonts/model/evaluation.py:207\u001b[0m, in \u001b[0;36mevaluate_forecasts\u001b[0;34m(forecasts, test_data, metrics, axis, batch_size, mask_invalid_label, allow_nan_forecast, seasonality)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_forecasts\u001b[39m(\n\u001b[1;32m    183\u001b[0m     forecasts: Iterable[Forecast],\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    191\u001b[0m     seasonality: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    192\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m    193\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m    Evaluate ``forecasts`` by comparing them with ``test_data``, according to\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m    ``metrics``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    Return results as a Pandas ``DataFrame``.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 207\u001b[0m     metrics_values \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_forecasts_raw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforecasts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforecasts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_invalid_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_invalid_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan_forecast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan_forecast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseasonality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseasonality\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m     index0 \u001b[38;5;241m=\u001b[39m metrics_values\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__index_0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    219\u001b[0m     metric_shape \u001b[38;5;241m=\u001b[39m metrics_values[first(metrics_values)]\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m/export/exp-series/miniconda3/envs/bench_oss/lib/python3.10/site-packages/gluonts/model/evaluation.py:166\u001b[0m, in \u001b[0;36mevaluate_forecasts_raw\u001b[0;34m(forecasts, test_data, metrics, axis, batch_size, mask_invalid_label, allow_nan_forecast, seasonality)\u001b[0m\n\u001b[1;32m    156\u001b[0m     data_batch \u001b[38;5;241m=\u001b[39m _get_data_batch(\n\u001b[1;32m    157\u001b[0m         input_batch,\n\u001b[1;32m    158\u001b[0m         label_batch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    162\u001b[0m         allow_nan_forecast\u001b[38;5;241m=\u001b[39mallow_nan_forecast,\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m evaluator \u001b[38;5;129;01min\u001b[39;00m evaluators\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m--> 166\u001b[0m         \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(forecast_batch))\n\u001b[1;32m    169\u001b[0m pbar\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/export/exp-series/miniconda3/envs/bench_oss/lib/python3.10/site-packages/gluonts/ev/metrics.py:111\u001b[0m, in \u001b[0;36mDirectMetric.update\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: Mapping[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/export/exp-series/miniconda3/envs/bench_oss/lib/python3.10/site-packages/gluonts/ev/stats.py:44\u001b[0m, in \u001b[0;36msquared_error\u001b[0;34m(data, forecast_type)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msquared_error\u001b[39m(\n\u001b[1;32m     42\u001b[0m     data: Dict[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray], forecast_type: \u001b[38;5;28mstr\u001b[39m\n\u001b[1;32m     43\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msquare(\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforecast_type\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/export/exp-series/miniconda3/envs/bench_oss/lib/python3.10/site-packages/gluonts/ev/stats.py:32\u001b[0m, in \u001b[0;36merror\u001b[0;34m(data, forecast_type)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror\u001b[39m(data: Dict[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray], forecast_type: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mforecast_type\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/export/exp-series/miniconda3/envs/bench_oss/lib/python3.10/collections/__init__.py:983\u001b[0m, in \u001b[0;36mChainMap.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mapping \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaps:\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 983\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m             \u001b[38;5;66;03m# can't use 'key in mapping' with defaultdict\u001b[39;00m\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/export/exp-series/miniconda3/envs/bench_oss/lib/python3.10/site-packages/gluonts/model/evaluation.py:45\u001b[0m, in \u001b[0;36mBatchForecast.__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[0;32m---> 45\u001b[0m     values \u001b[38;5;241m=\u001b[39m [forecast[name]\u001b[38;5;241m.\u001b[39mT \u001b[38;5;28;01mfor\u001b[39;00m forecast \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforecasts]\n\u001b[1;32m     46\u001b[0m     res \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(values, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(res)\u001b[38;5;241m.\u001b[39many():\n",
      "File \u001b[0;32m/export/exp-series/miniconda3/envs/bench_oss/lib/python3.10/site-packages/gluonts/model/evaluation.py:45\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[0;32m---> 45\u001b[0m     values \u001b[38;5;241m=\u001b[39m [\u001b[43mforecast\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mT \u001b[38;5;28;01mfor\u001b[39;00m forecast \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforecasts]\n\u001b[1;32m     46\u001b[0m     res \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(values, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(res)\u001b[38;5;241m.\u001b[39many():\n",
      "File \u001b[0;32m/export/exp-series/miniconda3/envs/bench_oss/lib/python3.10/site-packages/gluonts/model/forecast.py:290\u001b[0m, in \u001b[0;36mForecast.__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmedian\n\u001b[0;32m--> 290\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/export/exp-series/miniconda3/envs/bench_oss/lib/python3.10/site-packages/gluonts/torch/model/forecast.py:91\u001b[0m, in \u001b[0;36mDistributionForecast.quantile\u001b[0;34m(self, level)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquantile\u001b[39m(\u001b[38;5;28mself\u001b[39m, level: Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m     89\u001b[0m     level \u001b[38;5;241m=\u001b[39m Quantile\u001b[38;5;241m.\u001b[39mparse(level)\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m---> 91\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43micdf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     96\u001b[0m     )\n",
      "File \u001b[0;32m/export/exp-series/miniconda3/envs/bench_oss/lib/python3.10/site-packages/torch/distributions/transformed_distribution.py:210\u001b[0m, in \u001b[0;36mTransformedDistribution.icdf\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21micdf\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[1;32m    206\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m    Computes the inverse cumulative distribution function using\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m    transform(s) and computing the score of the base distribution.\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_monotonize_cdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_dist\u001b[38;5;241m.\u001b[39micdf(value)\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63488it [48:50, 21.85it/s]"
     ]
    }
   ],
   "source": [
    "from gluonts.model import evaluate_model\n",
    "from gluonts.torch.model.simple_feedforward import SimpleFeedForwardEstimator\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "from gluonts.time_feature import get_seasonality\n",
    "from gift_eval.data import Dataset\n",
    "# Iterate over all available datasets\n",
    "\n",
    "output_dir = \"../results/feedforward\"\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define the path for the CSV file\n",
    "csv_file_path = os.path.join(output_dir, 'all_results.csv')\n",
    "\n",
    "with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    \n",
    "    # Write the header\n",
    "    writer.writerow(['dataset', 'model', 'eval_metrics/MSE[mean]', 'eval_metrics/MSE[0.5]', 'eval_metrics/MAE[0.5]', 'eval_metrics/MASE[0.5]', 'eval_metrics/MAPE[0.5]', 'eval_metrics/sMAPE[0.5]', 'eval_metrics/MSIS', 'eval_metrics/RMSE[mean]', 'eval_metrics/NRMSE[mean]', 'eval_metrics/ND[0.5]', 'eval_metrics/mean_weighted_sum_quantile_loss', 'domain', 'num_variates'])\n",
    "    \n",
    "for ds_name in all_datasets:\n",
    "    ds_key = ds_name.split(\"/\")[0]\n",
    "    print(f\"Processing dataset: {ds_name}\")\n",
    "    terms = [\"short\", \"medium\", \"long\"]\n",
    "    for term in terms:\n",
    "        if (term == \"medium\" or term == \"long\") and ds_name not in med_long_datasets.split():\n",
    "            continue\n",
    "\n",
    "        # Initialize the dataset\n",
    "        to_univariate = False if Dataset(name=ds_name, term=term,to_univariate=False).target_dim == 1 else True\n",
    "        dataset = Dataset(name=ds_name, term=term, to_univariate=to_univariate)\n",
    "        season_length = get_seasonality(dataset.freq)\n",
    "        # Create mapping from dataset properties CSV\n",
    "       \n",
    "                \n",
    "        # Use mapping to get frequency for dataset\n",
    "        ds_config = f'{ds_name}/{term}' if '/' in ds_name else f'{ds_name}/{dataset_properties_map[ds_key][\"frequency\"]}/{term}'\n",
    "\n",
    "        estimator = SimpleFeedForwardEstimator(\n",
    "            prediction_length=dataset.prediction_length,\n",
    "            context_length=dataset.prediction_length,\n",
    "            trainer_kwargs=dict(\n",
    "                max_epochs=1,\n",
    "            )\n",
    "        )\n",
    "        predictor = estimator.train(dataset.validation_dataset)\n",
    "\n",
    "        # Measure the time taken for evaluation\n",
    "        res = evaluate_model(\n",
    "                predictor,\n",
    "                test_data=dataset.test_data,\n",
    "                metrics=metrics,\n",
    "                batch_size=512,\n",
    "                axis=None,\n",
    "                mask_invalid_label=True,\n",
    "                allow_nan_forecast=False,\n",
    "                seasonality=season_length,\n",
    "            )\n",
    "\n",
    "        # Append the results to the CSV file\n",
    "        with open(csv_file_path, 'a', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow([\n",
    "                ds_config, 'feedforward',\n",
    "                res['MSE[mean]'][0], res['MSE[0.5]'][0], res['MAE[0.5]'][0],\n",
    "                res['MASE[0.5]'][0], res['MAPE[0.5]'][0], res['sMAPE[0.5]'][0],\n",
    "                res['MSIS'][0], res['RMSE[mean]'][0], res['NRMSE[mean]'][0],\n",
    "                res['ND[0.5]'][0], res['mean_weighted_sum_quantile_loss'][0],dataset_properties_map[ds_key][\"domain\"],dataset_properties_map[ds_key][\"num_variates\"]\n",
    "            ])\n",
    "\n",
    "        print(f\"Results for {ds_name} have been written to {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Running the above cell will generate a csv file called `all_results.csv` under the `results/feedforward` folder containing the results for the Feed Forward model on the gift-eval benchmark. The csv file will look like this:\n",
    "\n",
    "```csv\n",
    "dataset,model,eval_metrics/MSE[mean],eval_metrics/MSE[0.5],eval_metrics/MAE[0.5],eval_metrics/MASE[0.5],eval_metrics/MAPE[0.5],eval_metrics/sMAPE[0.5],eval_metrics/MSIS,eval_metrics/RMSE[mean],eval_metrics/NRMSE[mean],eval_metrics/ND[0.5],eval_metrics/mean_weighted_sum_quantile_loss,domain,num_variates\n",
    "m4_weekly/W/short,feedforward,1448910.3029783587,1448910.3029783587,764.3635633169059,12.345394600259056,0.1595788812238858,0.15331997247127438,314.35590445280945,1203.706900777078,0.21929674306756633,0.13925519563500452,0.15997800028234835,Econ/Fin,1\n",
    "bizitobs_l2c/H/short,feedforward,241.18829055059524,241.18829055059524,12.045664953807044,1.1593927223085088,1.0907100979372752,1.0100947788783483,14.501148138388263,15.5302379424977,0.8371195987273939,0.6492921904913098,0.5449973232364873,Web/CloudOps,7\n",
    "bizitobs_l2c/H/medium,feedforward,81.86692708333334,81.86692708333334,6.16808093843006,0.6313417553056844,0.7273494340050158,0.8551737467447916,4.898049781903129,9.048034432037344,0.5478722280349564,0.37348666959888,0.3012130717159007,Web/CloudOps,7\n",
    "bizitobs_l2c/H/long,feedforward,87.75125248015873,87.75125248015873,6.178149026537699,0.6622176358901023,0.7759000447908542,0.7934493776351687,5.6998924604382974,9.367563849804213,0.5721978364002469,0.3773791737770806,0.31008587824774975,Web/CloudOps,7\n",
    "```\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bench_oss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
