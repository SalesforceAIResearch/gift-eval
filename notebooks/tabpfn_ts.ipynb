{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start: Running TabPFN-TS on gift-eval benchmark\n",
    "\n",
    "This notebook shows how to run TabPFN-TS on the gift-eval benchmark.\n",
    "\n",
    "Make sure you download the gift-eval benchmark and set the `GIFT-EVAL` environment variable correctly before running this notebook.\n",
    "\n",
    "We will use the `Dataset` class to load the data and run the model. If you have not already please check out the [dataset.ipynb](./dataset.ipynb) notebook to learn more about the `Dataset` class. We are going to just run the model on two datasets for brevity. But feel free to run on any dataset by changing the `short_datasets` and `med_long_datasets` variables below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up TabPFN-TS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "The predictor class of TabPFN-TS is included in `tabpfn-time-series` repository but not in the pip package. So we need to install it manually.\n",
    "\n",
    "1. Clone the TabPFN-TS repository\n",
    "2. Add the file to the Python path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/PriorLabs/tabpfn-time-series.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added tabpfn-time-series to Python path\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add both the main repository and the gift_eval subdirectory to the path\n",
    "sys.path.append(os.path.abspath(\"tabpfn-time-series\"))\n",
    "sys.path.append(os.path.abspath(\"tabpfn-time-series/gift_eval\"))\n",
    "print(\"Added tabpfn-time-series to Python path\")\n",
    "\n",
    "# Import the TabPFN time series predictor class\n",
    "# This is the main class we'll use for forecasting\n",
    "from tabpfn_ts_wrapper import TabPFNTSPredictor, TabPFNMode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabPFN-TS Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TabPFN-TS offers two ways to run the model:\n",
    "1. `TabPFNMode.LOCAL`: Run the model on the local machine (requires GPU)\n",
    "2. `TabPFNMode.CLIENT`: Run the model on the cloud (via `tabpfn-client`)\n",
    "\n",
    "In this notebook, we will use `TabPFNMode.LOCAL` mode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GIFT_EVAL_TABPFN_MODE = TabPFNMode.LOCAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the data and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# short_datasets = \"m4_yearly m4_quarterly m4_monthly m4_weekly m4_daily m4_hourly electricity/15T electricity/H electricity/D electricity/W solar/10T solar/H solar/D solar/W hospital covid_deaths us_births/D us_births/M us_births/W saugeenday/D saugeenday/M saugeenday/W temperature_rain_with_missing kdd_cup_2018_with_missing/H kdd_cup_2018_with_missing/D car_parts_with_missing restaurant hierarchical_sales/D hierarchical_sales/W LOOP_SEATTLE/5T LOOP_SEATTLE/H LOOP_SEATTLE/D SZ_TAXI/15T SZ_TAXI/H M_DENSE/H M_DENSE/D ett1/15T ett1/H ett1/D ett1/W ett2/15T ett2/H ett2/D ett2/W jena_weather/10T jena_weather/H jena_weather/D bitbrains_fast_storage/5T bitbrains_fast_storage/H bitbrains_rnd/5T bitbrains_rnd/H bizitobs_application bizitobs_service bizitobs_l2c/5T bizitobs_l2c/H\"\n",
    "short_datasets = \"m4_weekly\"\n",
    "\n",
    "# med_long_datasets = \"electricity/15T electricity/H solar/10T solar/H kdd_cup_2018_with_missing/H LOOP_SEATTLE/5T LOOP_SEATTLE/H SZ_TAXI/15T M_DENSE/H ett1/15T ett1/H ett2/15T ett2/H jena_weather/10T jena_weather/H bitbrains_fast_storage/5T bitbrains_rnd/5T bizitobs_application bizitobs_service bizitobs_l2c/5T bizitobs_l2c/H\"\n",
    "med_long_datasets = \"bizitobs_l2c/H\"\n",
    "\n",
    "# Get union of short and med_long datasets\n",
    "all_datasets = list(set(short_datasets.split() + med_long_datasets.split()))\n",
    "\n",
    "dataset_properties_map = json.load(open(\"dataset_properties.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.ev.metrics import (\n",
    "    MAE,\n",
    "    MAPE,\n",
    "    MASE,\n",
    "    MSE,\n",
    "    MSIS,\n",
    "    ND,\n",
    "    NRMSE,\n",
    "    RMSE,\n",
    "    SMAPE,\n",
    "    MeanWeightedSumQuantileLoss,\n",
    ")\n",
    "\n",
    "# Instantiate the metrics\n",
    "metrics = [\n",
    "    MSE(forecast_type=\"mean\"),\n",
    "    MSE(forecast_type=0.5),\n",
    "    MAE(),\n",
    "    MASE(),\n",
    "    MAPE(),\n",
    "    SMAPE(),\n",
    "    MSIS(),\n",
    "    RMSE(),\n",
    "    NRMSE(),\n",
    "    ND(),\n",
    "    MeanWeightedSumQuantileLoss(\n",
    "        quantile_levels=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Since `tabpfn-time-series` has implemented the predictor class, we can use it to predict on the gift-eval benchmark datasets. We will use the `evaluate_model` function to evaluate the model. This function is a helper function to evaluate the model on the test data and return the results in a dictionary. We are going to follow the naming conventions explained in the [README](../README.md) file to store the results in a csv file called `all_results.csv` under the `results/tabpfn_ts` folder.\n",
    "\n",
    "The first column in the csv file is the dataset config name which is a combination of the dataset name, frequency and the term:\n",
    "\n",
    "```python\n",
    "f\"{dataset_name}/{freq}/{term}\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m4_weekly', 'bizitobs_l2c/H']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "class WarningFilter(logging.Filter):\n",
    "    def __init__(self, text_to_filter):\n",
    "        super().__init__()\n",
    "        self.text_to_filter = text_to_filter\n",
    "\n",
    "    def filter(self, record):\n",
    "        return self.text_to_filter not in record.getMessage()\n",
    "\n",
    "\n",
    "gts_logger = logging.getLogger(\"gluonts.model.forecast\")\n",
    "gts_logger.addFilter(\n",
    "    WarningFilter(\"The mean prediction is not stored in the forecast data\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: m4_weekly (1 of 2)\n",
      "Dataset size: 359\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "GPU is required for local TabPFN inference",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 79\u001b[0m\n\u001b[1;32m     77\u001b[0m season_length \u001b[38;5;241m=\u001b[39m get_seasonality(dataset\u001b[38;5;241m.\u001b[39mfreq)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataset\u001b[38;5;241m.\u001b[39mtest_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 79\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[43mTabPFNTSPredictor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mds_prediction_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mds_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtabpfn_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGIFT_EVAL_TABPFN_MODE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# Measure the time taken for evaluation\u001b[39;00m\n\u001b[1;32m     86\u001b[0m res \u001b[38;5;241m=\u001b[39m evaluate_model(\n\u001b[1;32m     87\u001b[0m     predictor,\n\u001b[1;32m     88\u001b[0m     test_data\u001b[38;5;241m=\u001b[39mdataset\u001b[38;5;241m.\u001b[39mtest_data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m     seasonality\u001b[38;5;241m=\u001b[39mseason_length,\n\u001b[1;32m     95\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/freiburg-cs/gift-eval/notebooks/tabpfn-time-series/gift_eval/tabpfn_ts_wrapper.py:38\u001b[0m, in \u001b[0;36mTabPFNTSPredictor.__init__\u001b[0;34m(self, ds_prediction_length, ds_freq, tabpfn_mode, context_length, debug)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds_prediction_length \u001b[38;5;241m=\u001b[39m ds_prediction_length\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds_freq \u001b[38;5;241m=\u001b[39m ds_freq\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtabpfn_predictor \u001b[38;5;241m=\u001b[39m \u001b[43mTabPFNTimeSeriesPredictor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtabpfn_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtabpfn_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_length \u001b[38;5;241m=\u001b[39m context_length\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;241m=\u001b[39m debug\n",
      "File \u001b[0;32m~/Documents/freiburg-cs/gift-eval/notebooks/tabpfn-time-series/tabpfn_time_series/predictor.py:33\u001b[0m, in \u001b[0;36mTabPFNTimeSeriesPredictor.__init__\u001b[0;34m(self, tabpfn_mode, config)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     25\u001b[0m     tabpfn_mode: TabPFNMode \u001b[38;5;241m=\u001b[39m TabPFNMode\u001b[38;5;241m.\u001b[39mCLIENT,\n\u001b[1;32m     26\u001b[0m     config: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m TABPFN_TS_DEFAULT_CONFIG,\n\u001b[1;32m     27\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m     worker_mapping \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     29\u001b[0m         TabPFNMode\u001b[38;5;241m.\u001b[39mCLIENT: \u001b[38;5;28;01mlambda\u001b[39;00m: TabPFNClient(config),\n\u001b[1;32m     30\u001b[0m         TabPFNMode\u001b[38;5;241m.\u001b[39mLOCAL: \u001b[38;5;28;01mlambda\u001b[39;00m: LocalTabPFN(config),\n\u001b[1;32m     31\u001b[0m         TabPFNMode\u001b[38;5;241m.\u001b[39mMOCK: \u001b[38;5;28;01mlambda\u001b[39;00m: MockTabPFN(config),\n\u001b[1;32m     32\u001b[0m     }\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtabpfn_worker \u001b[38;5;241m=\u001b[39m \u001b[43mworker_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtabpfn_mode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/freiburg-cs/gift-eval/notebooks/tabpfn-time-series/tabpfn_time_series/predictor.py:30\u001b[0m, in \u001b[0;36mTabPFNTimeSeriesPredictor.__init__.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     25\u001b[0m     tabpfn_mode: TabPFNMode \u001b[38;5;241m=\u001b[39m TabPFNMode\u001b[38;5;241m.\u001b[39mCLIENT,\n\u001b[1;32m     26\u001b[0m     config: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m TABPFN_TS_DEFAULT_CONFIG,\n\u001b[1;32m     27\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m     worker_mapping \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     29\u001b[0m         TabPFNMode\u001b[38;5;241m.\u001b[39mCLIENT: \u001b[38;5;28;01mlambda\u001b[39;00m: TabPFNClient(config),\n\u001b[0;32m---> 30\u001b[0m         TabPFNMode\u001b[38;5;241m.\u001b[39mLOCAL: \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mLocalTabPFN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     31\u001b[0m         TabPFNMode\u001b[38;5;241m.\u001b[39mMOCK: \u001b[38;5;28;01mlambda\u001b[39;00m: MockTabPFN(config),\n\u001b[1;32m     32\u001b[0m     }\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtabpfn_worker \u001b[38;5;241m=\u001b[39m worker_mapping[tabpfn_mode]()\n",
      "File \u001b[0;32m~/Documents/freiburg-cs/gift-eval/notebooks/tabpfn-time-series/tabpfn_time_series/tabpfn_worker.py:148\u001b[0m, in \u001b[0;36mLocalTabPFN.__init__\u001b[0;34m(self, config, num_workers_per_gpu)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Only support GPU for now (inference on CPU takes too long)\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU is required for local TabPFN inference\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    151\u001b[0m     config, num_workers\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count() \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_workers_per_gpu\n\u001b[1;32m    152\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: GPU is required for local TabPFN inference"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "from gluonts.model import evaluate_model\n",
    "from gluonts.time_feature import get_seasonality\n",
    "\n",
    "from gift_eval.data import Dataset\n",
    "\n",
    "# Iterate over all available datasets\n",
    "model_name = \"tabpfn_ts\"\n",
    "output_dir = f\"../results/{model_name}\"\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define the path for the CSV file\n",
    "csv_file_path = os.path.join(output_dir, \"all_results.csv\")\n",
    "\n",
    "pretty_names = {\n",
    "    \"saugeenday\": \"saugeen\",\n",
    "    \"temperature_rain_with_missing\": \"temperature_rain\",\n",
    "    \"kdd_cup_2018_with_missing\": \"kdd_cup_2018\",\n",
    "    \"car_parts_with_missing\": \"car_parts\",\n",
    "}\n",
    "\n",
    "with open(csv_file_path, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write the header\n",
    "    writer.writerow(\n",
    "        [\n",
    "            \"dataset\",\n",
    "            \"model\",\n",
    "            \"eval_metrics/MSE[mean]\",\n",
    "            \"eval_metrics/MSE[0.5]\",\n",
    "            \"eval_metrics/MAE[0.5]\",\n",
    "            \"eval_metrics/MASE[0.5]\",\n",
    "            \"eval_metrics/MAPE[0.5]\",\n",
    "            \"eval_metrics/sMAPE[0.5]\",\n",
    "            \"eval_metrics/MSIS\",\n",
    "            \"eval_metrics/RMSE[mean]\",\n",
    "            \"eval_metrics/NRMSE[mean]\",\n",
    "            \"eval_metrics/ND[0.5]\",\n",
    "            \"eval_metrics/mean_weighted_sum_quantile_loss\",\n",
    "            \"domain\",\n",
    "            \"num_variates\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "for ds_num, ds_name in enumerate(all_datasets):\n",
    "    ds_key = ds_name.split(\"/\")[0]\n",
    "    print(f\"Processing dataset: {ds_name} ({ds_num + 1} of {len(all_datasets)})\")\n",
    "    terms = [\"short\", \"medium\", \"long\"]\n",
    "    for term in terms:\n",
    "        if (\n",
    "            term == \"medium\" or term == \"long\"\n",
    "        ) and ds_name not in med_long_datasets.split():\n",
    "            continue\n",
    "\n",
    "        if \"/\" in ds_name:\n",
    "            ds_key = ds_name.split(\"/\")[0]\n",
    "            ds_freq = ds_name.split(\"/\")[1]\n",
    "            ds_key = ds_key.lower()\n",
    "            ds_key = pretty_names.get(ds_key, ds_key)\n",
    "        else:\n",
    "            ds_key = ds_name.lower()\n",
    "            ds_key = pretty_names.get(ds_key, ds_key)\n",
    "            ds_freq = dataset_properties_map[ds_key][\"frequency\"]\n",
    "        ds_config = f\"{ds_key}/{ds_freq}/{term}\"\n",
    "\n",
    "        # Initialize the dataset\n",
    "        to_univariate = (\n",
    "            False\n",
    "            if Dataset(name=ds_name, term=term, to_univariate=False).target_dim == 1\n",
    "            else True\n",
    "        )\n",
    "        dataset = Dataset(name=ds_name, term=term, to_univariate=to_univariate)\n",
    "        season_length = get_seasonality(dataset.freq)\n",
    "        print(f\"Dataset size: {len(dataset.test_data)}\")\n",
    "        predictor = TabPFNTSPredictor(\n",
    "            ds_prediction_length=dataset.prediction_length,\n",
    "            ds_freq=dataset.freq,\n",
    "            tabpfn_mode=GIFT_EVAL_TABPFN_MODE,\n",
    "            context_length=4096,\n",
    "        )\n",
    "        # Measure the time taken for evaluation\n",
    "        res = evaluate_model(\n",
    "            predictor,\n",
    "            test_data=dataset.test_data,\n",
    "            metrics=metrics,\n",
    "            batch_size=1024,\n",
    "            axis=None,\n",
    "            mask_invalid_label=True,\n",
    "            allow_nan_forecast=False,\n",
    "            seasonality=season_length,\n",
    "        )\n",
    "\n",
    "        # Append the results to the CSV file\n",
    "        with open(csv_file_path, \"a\", newline=\"\") as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(\n",
    "                [\n",
    "                    ds_config,\n",
    "                    model_name,\n",
    "                    res[\"MSE[mean]\"][0],\n",
    "                    res[\"MSE[0.5]\"][0],\n",
    "                    res[\"MAE[0.5]\"][0],\n",
    "                    res[\"MASE[0.5]\"][0],\n",
    "                    res[\"MAPE[0.5]\"][0],\n",
    "                    res[\"sMAPE[0.5]\"][0],\n",
    "                    res[\"MSIS\"][0],\n",
    "                    res[\"RMSE[mean]\"][0],\n",
    "                    res[\"NRMSE[mean]\"][0],\n",
    "                    res[\"ND[0.5]\"][0],\n",
    "                    res[\"mean_weighted_sum_quantile_loss\"][0],\n",
    "                    dataset_properties_map[ds_key][\"domain\"],\n",
    "                    dataset_properties_map[ds_key][\"num_variates\"],\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        print(f\"Results for {ds_name} have been written to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Running the above cell will generate a csv file called `all_results.csv` under the `results/tabpfn_ts` folder containing the results for the Chronos model on the gift-eval benchmark. We can display the csv file using the follow code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>eval_metrics/MSE[mean]</th>\n",
       "      <th>eval_metrics/MSE[0.5]</th>\n",
       "      <th>eval_metrics/MAE[0.5]</th>\n",
       "      <th>eval_metrics/MASE[0.5]</th>\n",
       "      <th>eval_metrics/MAPE[0.5]</th>\n",
       "      <th>eval_metrics/sMAPE[0.5]</th>\n",
       "      <th>eval_metrics/MSIS</th>\n",
       "      <th>eval_metrics/RMSE[mean]</th>\n",
       "      <th>eval_metrics/NRMSE[mean]</th>\n",
       "      <th>eval_metrics/ND[0.5]</th>\n",
       "      <th>eval_metrics/mean_weighted_sum_quantile_loss</th>\n",
       "      <th>domain</th>\n",
       "      <th>num_variates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m4_weekly/W/short</td>\n",
       "      <td>tabpfn_ts</td>\n",
       "      <td>204228.785503</td>\n",
       "      <td>204228.785503</td>\n",
       "      <td>244.979569</td>\n",
       "      <td>2.036775</td>\n",
       "      <td>0.060409</td>\n",
       "      <td>0.061283</td>\n",
       "      <td>16.270365</td>\n",
       "      <td>451.916790</td>\n",
       "      <td>0.082332</td>\n",
       "      <td>0.044631</td>\n",
       "      <td>0.035902</td>\n",
       "      <td>Econ/Fin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bizitobs_l2c/H/short</td>\n",
       "      <td>tabpfn_ts</td>\n",
       "      <td>92.610989</td>\n",
       "      <td>92.610989</td>\n",
       "      <td>6.675249</td>\n",
       "      <td>0.654242</td>\n",
       "      <td>0.755953</td>\n",
       "      <td>0.720848</td>\n",
       "      <td>6.131648</td>\n",
       "      <td>9.623460</td>\n",
       "      <td>0.518729</td>\n",
       "      <td>0.359813</td>\n",
       "      <td>0.295209</td>\n",
       "      <td>Web/CloudOps</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bizitobs_l2c/H/medium</td>\n",
       "      <td>tabpfn_ts</td>\n",
       "      <td>124.828985</td>\n",
       "      <td>124.828985</td>\n",
       "      <td>7.720654</td>\n",
       "      <td>0.783250</td>\n",
       "      <td>1.022755</td>\n",
       "      <td>0.821980</td>\n",
       "      <td>7.118701</td>\n",
       "      <td>11.172689</td>\n",
       "      <td>0.676523</td>\n",
       "      <td>0.467497</td>\n",
       "      <td>0.392065</td>\n",
       "      <td>Web/CloudOps</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bizitobs_l2c/H/long</td>\n",
       "      <td>tabpfn_ts</td>\n",
       "      <td>160.193677</td>\n",
       "      <td>160.193677</td>\n",
       "      <td>8.947659</td>\n",
       "      <td>0.925419</td>\n",
       "      <td>1.340661</td>\n",
       "      <td>0.827672</td>\n",
       "      <td>7.971628</td>\n",
       "      <td>12.656764</td>\n",
       "      <td>0.773112</td>\n",
       "      <td>0.546549</td>\n",
       "      <td>0.447120</td>\n",
       "      <td>Web/CloudOps</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dataset      model  eval_metrics/MSE[mean]   \n",
       "0      m4_weekly/W/short  tabpfn_ts           204228.785503  \\\n",
       "1   bizitobs_l2c/H/short  tabpfn_ts               92.610989   \n",
       "2  bizitobs_l2c/H/medium  tabpfn_ts              124.828985   \n",
       "3    bizitobs_l2c/H/long  tabpfn_ts              160.193677   \n",
       "\n",
       "   eval_metrics/MSE[0.5]  eval_metrics/MAE[0.5]  eval_metrics/MASE[0.5]   \n",
       "0          204228.785503             244.979569                2.036775  \\\n",
       "1              92.610989               6.675249                0.654242   \n",
       "2             124.828985               7.720654                0.783250   \n",
       "3             160.193677               8.947659                0.925419   \n",
       "\n",
       "   eval_metrics/MAPE[0.5]  eval_metrics/sMAPE[0.5]  eval_metrics/MSIS   \n",
       "0                0.060409                 0.061283          16.270365  \\\n",
       "1                0.755953                 0.720848           6.131648   \n",
       "2                1.022755                 0.821980           7.118701   \n",
       "3                1.340661                 0.827672           7.971628   \n",
       "\n",
       "   eval_metrics/RMSE[mean]  eval_metrics/NRMSE[mean]  eval_metrics/ND[0.5]   \n",
       "0               451.916790                  0.082332              0.044631  \\\n",
       "1                 9.623460                  0.518729              0.359813   \n",
       "2                11.172689                  0.676523              0.467497   \n",
       "3                12.656764                  0.773112              0.546549   \n",
       "\n",
       "   eval_metrics/mean_weighted_sum_quantile_loss        domain  num_variates  \n",
       "0                                      0.035902      Econ/Fin             1  \n",
       "1                                      0.295209  Web/CloudOps             7  \n",
       "2                                      0.392065  Web/CloudOps             7  \n",
       "3                                      0.447120  Web/CloudOps             7  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(f\"../results/{model_name}/all_results.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabpfn-ts-gift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
