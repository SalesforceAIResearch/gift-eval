{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start: Running Foundation Model Moirai 2 on gift-eval benchmark\n",
    "\n",
    "This notebook shows how to run the Foundation Model Moirai on the gift-eval benchmark.\n",
    "\n",
    "Make sure you download the gift-eval benchmark and set the `GIFT-EVAL` environment variable correctly before running this notebook.\n",
    "\n",
    "We will use the `Dataset` class to load the data and run the model. If you have not already please check out the [dataset.ipynb](./dataset.ipynb) notebook to learn more about the `Dataset` class. We are going to just run the model on two datasets for brevity. But feel free to run on any dataset by changing the `short_datasets` and `med_long_datasets` variables below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moirai Predictor\n",
    "We first install moirai via  \n",
    "1. `pip install uni2ts`. \n",
    "\n",
    "Its predictor has already inherited `gluonts.torch.PyTorchPredictor` which is compatible with the `gluonts` evaluation pipeline. Note that there is a dependency conflict that `uni2ts` uses `gluonts~=0.14.3` for its evaluation while `gift_eval` requires `gluonts~=0.15.1`. \n",
    "Here, we need to reinstall it via \n",
    "\n",
    "2. `pip install gluonts==0.15.1`\n",
    "\n",
    "We then load the model with initial hyperparameters, like `prediction_length`, `context_length`, `patch_size`, `num_samples`, etc. You can find more details about these hyperparameters from <https://github.com/SalesforceAIResearch/uni2ts/blob/main/example/moirai_forecast_pandas.ipynb>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iaksu/miniforge3/envs/gift_eval/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "import numpy as np\n",
    "import torch\n",
    "from gluonts.itertools import batcher\n",
    "from gluonts.model.forecast import QuantileForecast\n",
    "\n",
    "from uni2ts.model.moirai2 import Moirai2Forecast, Moirai2Module\n",
    "import logging\n",
    "# skip the no mean value warning from QuantileForecast\n",
    "logging.getLogger(\"gluonts.model.forecast\").setLevel(logging.ERROR)\n",
    "\n",
    "def get_device(device=\"auto\"):\n",
    "    if device == \"auto\":\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda\")\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "    else:\n",
    "        device = torch.device(device)\n",
    "    return device\n",
    "\n",
    "class MoiraiQuantilePredictor:\n",
    "    def __init__(\n",
    "            self,\n",
    "            model_path: str,\n",
    "            prediction_length: int = 100,\n",
    "            context_length: int = 4000,\n",
    "            target_dim: int =1,\n",
    "            feat_dynamic_real_dim: int =0,\n",
    "            past_feat_dynamic_real_dim: int =0,\n",
    "            device: str = 'auto',\n",
    "            batch_size: int = 2048,\n",
    "            quantile_levels: tuple[float] = (0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9),\n",
    "        ):\n",
    "        self.model_path = model_path\n",
    "        self.prediction_length = prediction_length\n",
    "        self.context_length = context_length\n",
    "        self.target_dim = target_dim\n",
    "        self.feat_dynamic_real_dim = feat_dynamic_real_dim\n",
    "        self.past_feat_dynamic_real_dim = past_feat_dynamic_real_dim\n",
    "        self.device = get_device(device)\n",
    "        self.batch_size = batch_size\n",
    "        self.quantile_levels = quantile_levels\n",
    "        self.model = Moirai2Forecast(\n",
    "            module=Moirai2Module.from_pretrained(self.model_path),\n",
    "            prediction_length=self.prediction_length,\n",
    "            context_length=self.context_length,\n",
    "            target_dim=self.target_dim,\n",
    "            feat_dynamic_real_dim=self.feat_dynamic_real_dim,\n",
    "            past_feat_dynamic_real_dim=self.past_feat_dynamic_real_dim,\n",
    "        ).to(self.device)\n",
    "\n",
    "    def predict(self, test_data_input):\n",
    "        while True:\n",
    "            try:\n",
    "                print(\"Model - MoiraiQuantile loaded with batch_size:\", self.batch_size)\n",
    "                # Generate forecast samples\n",
    "                forecast_quantiles = []\n",
    "                for batch in (batcher(test_data_input, batch_size=self.batch_size)):\n",
    "                    past_target = [entry[\"target\"] for entry in batch]\n",
    "                    forecasts = self.model.predict(past_target) # full_forecasts shape: (batch num_quantiles future_time #tgt)\n",
    "                    forecast_quantiles.append(forecasts)\n",
    "                forecast_quantiles = np.concatenate(forecast_quantiles)\n",
    "                break\n",
    "            except torch.cuda.OutOfMemoryError:\n",
    "                print(\n",
    "                    f\"OutOfMemoryError at batch_size {self.batch_size}, reducing to {self.batch_size // 2}\"\n",
    "                )\n",
    "                self.batch_size //= 2\n",
    "\n",
    "        # Convert forecast samples into gluonts QuantileForecast objects\n",
    "        quantile_forecasts = []\n",
    "        for item, ts in zip(forecast_quantiles, test_data_input):\n",
    "            forecast_start_date = ts[\"start\"] + len(ts[\"target\"])\n",
    "            quantile_forecasts.append(\n",
    "                QuantileForecast(\n",
    "                item_id = ts[\"item_id\"],\n",
    "                forecast_arrays=item,\n",
    "                start_date=forecast_start_date,\n",
    "                forecast_keys=list(map(str, self.quantile_levels)))\n",
    "            )\n",
    "        return quantile_forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# short_datasets = \"m4_yearly m4_quarterly m4_monthly m4_weekly m4_daily m4_hourly electricity/15T electricity/H electricity/D electricity/W solar/10T solar/H solar/D solar/W hospital covid_deaths us_births/D us_births/M us_births/W saugeenday/D saugeenday/M saugeenday/W temperature_rain_with_missing kdd_cup_2018_with_missing/H kdd_cup_2018_with_missing/D car_parts_with_missing restaurant hierarchical_sales/D hierarchical_sales/W LOOP_SEATTLE/5T LOOP_SEATTLE/H LOOP_SEATTLE/D SZ_TAXI/15T SZ_TAXI/H M_DENSE/H M_DENSE/D ett1/15T ett1/H ett1/D ett1/W ett2/15T ett2/H ett2/D ett2/W jena_weather/10T jena_weather/H jena_weather/D bitbrains_fast_storage/5T bitbrains_fast_storage/H bitbrains_rnd/5T bitbrains_rnd/H bizitobs_application bizitobs_service bizitobs_l2c/5T bizitobs_l2c/H\"\n",
    "short_datasets = \"m4_weekly\"\n",
    "\n",
    "# med_long_datasets = \"electricity/15T electricity/H solar/10T solar/H kdd_cup_2018_with_missing/H LOOP_SEATTLE/5T LOOP_SEATTLE/H SZ_TAXI/15T M_DENSE/H ett1/15T ett1/H ett2/15T ett2/H jena_weather/10T jena_weather/H bitbrains_fast_storage/5T bitbrains_rnd/5T bizitobs_application bizitobs_service bizitobs_l2c/5T bizitobs_l2c/H\"\n",
    "med_long_datasets = \"bizitobs_l2c/H\"\n",
    "\n",
    "# Get union of short and med_long datasets\n",
    "all_datasets = list(set(short_datasets.split() + med_long_datasets.split()))\n",
    "\n",
    "dataset_properties_map = json.load(open(\"dataset_properties.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.ev.metrics import (\n",
    "    MSE,\n",
    "    MAE,\n",
    "    MASE,\n",
    "    MAPE,\n",
    "    SMAPE,\n",
    "    MSIS,\n",
    "    RMSE,\n",
    "    NRMSE,\n",
    "    ND,\n",
    "    MeanWeightedSumQuantileLoss,\n",
    ")\n",
    "\n",
    "# Instantiate the metrics\n",
    "metrics = [\n",
    "    MSE(forecast_type=\"mean\"),\n",
    "    MSE(forecast_type=0.5),\n",
    "    MAE(),\n",
    "    MASE(),\n",
    "    MAPE(),\n",
    "    SMAPE(),\n",
    "    MSIS(),\n",
    "    RMSE(),\n",
    "    NRMSE(),\n",
    "    ND(),\n",
    "    MeanWeightedSumQuantileLoss(\n",
    "        quantile_levels=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Now that we have our predictor class, we can use it to predict on the gift-eval benchmark datasets. We will use the `evaluate_model` function to evaluate the model. This function is a helper function to evaluate the model on the test data and return the results in a dictionary. We are going to follow the naming conventions explained in the [README](../README.md) file to store the results in a csv file called `all_results.csv` under the `results/moirai_small` folder.\n",
    "\n",
    "The first column in the csv file is the dataset config name which is a combination of the dataset name, frequency and the term:\n",
    "\n",
    "```python\n",
    "f\"{dataset_name}/{freq}/{term}\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: bizitobs_l2c/H\n",
      "Model - MoiraiQuantile loaded with batch_size: 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [00:00, 997.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for bizitobs_l2c/H have been written to ../results/moirai_small/all_results.csv\n",
      "Model - MoiraiQuantile loaded with batch_size: 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 710.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for bizitobs_l2c/H have been written to ../results/moirai_small/all_results.csv\n",
      "Model - MoiraiQuantile loaded with batch_size: 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 692.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for bizitobs_l2c/H have been written to ../results/moirai_small/all_results.csv\n",
      "Processing dataset: m4_weekly\n",
      "Model - MoiraiQuantile loaded with batch_size: 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "359it [00:00, 1179.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for m4_weekly have been written to ../results/moirai_small/all_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from gluonts.model import evaluate_model\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "from gluonts.time_feature import get_seasonality\n",
    "from gift_eval.data import Dataset\n",
    "\n",
    "# Iterate over all available datasets\n",
    "\n",
    "output_dir = \"../results/Moirai2\"\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "pretty_names = {\n",
    "    \"saugeenday\": \"saugeen\",\n",
    "    \"temperature_rain_with_missing\": \"temperature_rain\",\n",
    "    \"kdd_cup_2018_with_missing\": \"kdd_cup_2018\",\n",
    "    \"car_parts_with_missing\": \"car_parts\",\n",
    "}\n",
    "\n",
    "# Define the path for the CSV file\n",
    "csv_file_path = os.path.join(output_dir, \"all_results.csv\")\n",
    "\n",
    "with open(csv_file_path, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write the header\n",
    "    writer.writerow(\n",
    "        [\n",
    "            \"dataset\",\n",
    "            \"model\",\n",
    "            \"eval_metrics/MSE[mean]\",\n",
    "            \"eval_metrics/MSE[0.5]\",\n",
    "            \"eval_metrics/MAE[0.5]\",\n",
    "            \"eval_metrics/MASE[0.5]\",\n",
    "            \"eval_metrics/MAPE[0.5]\",\n",
    "            \"eval_metrics/sMAPE[0.5]\",\n",
    "            \"eval_metrics/MSIS\",\n",
    "            \"eval_metrics/RMSE[mean]\",\n",
    "            \"eval_metrics/NRMSE[mean]\",\n",
    "            \"eval_metrics/ND[0.5]\",\n",
    "            \"eval_metrics/mean_weighted_sum_quantile_loss\",\n",
    "            \"domain\",\n",
    "            \"num_variates\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "for ds_name in all_datasets:\n",
    "    ds_key = ds_name.split(\"/\")[0]\n",
    "    print(f\"Processing dataset: {ds_name}\")\n",
    "    terms = [\"short\", \"medium\", \"long\"]\n",
    "    for term in terms:\n",
    "        if (\n",
    "            term == \"medium\" or term == \"long\"\n",
    "        ) and ds_name not in med_long_datasets.split():\n",
    "            continue\n",
    "\n",
    "        if \"/\" in ds_name:\n",
    "            ds_key = ds_name.split(\"/\")[0]\n",
    "            ds_freq = ds_name.split(\"/\")[1]\n",
    "            ds_key = ds_key.lower()\n",
    "            ds_key = pretty_names.get(ds_key, ds_key)\n",
    "        else:\n",
    "            ds_key = ds_name.lower()\n",
    "            ds_key = pretty_names.get(ds_key, ds_key)\n",
    "            ds_freq = dataset_properties_map[ds_key][\"frequency\"]\n",
    "\n",
    "        ds_config = f\"{ds_key}/{ds_freq}/{term}\"\n",
    "\n",
    "        # Initialize the dataset, since Moirai support multivariate time series forecast, it does not require\n",
    "        # to convert the original data into univariate\n",
    "        to_univariate = False if Dataset(name=ds_name, term=term,to_univariate=False).target_dim == 1 else True\n",
    "        dataset = Dataset(name=ds_name, term=term, to_univariate=to_univariate)\n",
    "\n",
    "        predictor = MoiraiQuantilePredictor(\n",
    "            model_path=f\"Salesforce/moirai-2.0-R-small\",\n",
    "            prediction_length=dataset.prediction_length,\n",
    "            context_length=4000,\n",
    "            target_dim=1,\n",
    "            past_feat_dynamic_real_dim=dataset.past_feat_dynamic_real_dim,\n",
    "            batch_size=512,\n",
    "        )\n",
    "\n",
    "        season_length = get_seasonality(dataset.freq)\n",
    "\n",
    "        res = evaluate_model(\n",
    "            predictor,\n",
    "            test_data=dataset.test_data,\n",
    "            metrics=metrics,\n",
    "            batch_size=512,\n",
    "            axis=None,\n",
    "            mask_invalid_label=True,\n",
    "            allow_nan_forecast=False,\n",
    "            seasonality=season_length,\n",
    "        )\n",
    "\n",
    "        # Append the results to the CSV file\n",
    "        with open(csv_file_path, \"a\", newline=\"\") as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(\n",
    "                [\n",
    "                    ds_config,\n",
    "                    \"moirai_small\",\n",
    "                    res[\"MSE[mean]\"][0],\n",
    "                    res[\"MSE[0.5]\"][0],\n",
    "                    res[\"MAE[0.5]\"][0],\n",
    "                    res[\"MASE[0.5]\"][0],\n",
    "                    res[\"MAPE[0.5]\"][0],\n",
    "                    res[\"sMAPE[0.5]\"][0],\n",
    "                    res[\"MSIS\"][0],\n",
    "                    res[\"RMSE[mean]\"][0],\n",
    "                    res[\"NRMSE[mean]\"][0],\n",
    "                    res[\"ND[0.5]\"][0],\n",
    "                    res[\"mean_weighted_sum_quantile_loss\"][0],\n",
    "                    dataset_properties_map[ds_key][\"domain\"],\n",
    "                    dataset_properties_map[ds_key][\"num_variates\"],\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        print(f\"Results for {ds_name} have been written to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Running the above cell will generate a csv file called `all_results.csv` under the `results/moirai_small` folder containing the results for the Moirai model on the gift-eval benchmark. The csv file will look like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>eval_metrics/MSE[mean]</th>\n",
       "      <th>eval_metrics/MSE[0.5]</th>\n",
       "      <th>eval_metrics/MAE[0.5]</th>\n",
       "      <th>eval_metrics/MASE[0.5]</th>\n",
       "      <th>eval_metrics/MAPE[0.5]</th>\n",
       "      <th>eval_metrics/sMAPE[0.5]</th>\n",
       "      <th>eval_metrics/MSIS</th>\n",
       "      <th>eval_metrics/RMSE[mean]</th>\n",
       "      <th>eval_metrics/NRMSE[mean]</th>\n",
       "      <th>eval_metrics/ND[0.5]</th>\n",
       "      <th>eval_metrics/mean_weighted_sum_quantile_loss</th>\n",
       "      <th>domain</th>\n",
       "      <th>num_variates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bizitobs_l2c/H/short</td>\n",
       "      <td>moirai_small</td>\n",
       "      <td>67.850121</td>\n",
       "      <td>67.850121</td>\n",
       "      <td>5.013020</td>\n",
       "      <td>0.502710</td>\n",
       "      <td>0.478462</td>\n",
       "      <td>0.636955</td>\n",
       "      <td>7.536384</td>\n",
       "      <td>8.237118</td>\n",
       "      <td>0.444002</td>\n",
       "      <td>0.270215</td>\n",
       "      <td>0.234670</td>\n",
       "      <td>Web/CloudOps</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bizitobs_l2c/H/medium</td>\n",
       "      <td>moirai_small</td>\n",
       "      <td>73.605469</td>\n",
       "      <td>73.605469</td>\n",
       "      <td>5.040342</td>\n",
       "      <td>0.508575</td>\n",
       "      <td>0.561661</td>\n",
       "      <td>0.795054</td>\n",
       "      <td>10.486613</td>\n",
       "      <td>8.579363</td>\n",
       "      <td>0.519493</td>\n",
       "      <td>0.305200</td>\n",
       "      <td>0.273815</td>\n",
       "      <td>Web/CloudOps</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bizitobs_l2c/H/long</td>\n",
       "      <td>moirai_small</td>\n",
       "      <td>99.568849</td>\n",
       "      <td>99.568849</td>\n",
       "      <td>5.755020</td>\n",
       "      <td>0.610783</td>\n",
       "      <td>0.712003</td>\n",
       "      <td>0.807344</td>\n",
       "      <td>15.002673</td>\n",
       "      <td>9.978419</td>\n",
       "      <td>0.609511</td>\n",
       "      <td>0.351533</td>\n",
       "      <td>0.321291</td>\n",
       "      <td>Web/CloudOps</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m4_weekly/W/short</td>\n",
       "      <td>moirai_small</td>\n",
       "      <td>320634.706664</td>\n",
       "      <td>320634.706664</td>\n",
       "      <td>278.256482</td>\n",
       "      <td>2.123471</td>\n",
       "      <td>0.067205</td>\n",
       "      <td>0.068345</td>\n",
       "      <td>14.761419</td>\n",
       "      <td>566.246154</td>\n",
       "      <td>0.103161</td>\n",
       "      <td>0.050694</td>\n",
       "      <td>0.040013</td>\n",
       "      <td>Econ/Fin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dataset         model  eval_metrics/MSE[mean]   \n",
       "0   bizitobs_l2c/H/short  moirai_small               67.850121  \\\n",
       "1  bizitobs_l2c/H/medium  moirai_small               73.605469   \n",
       "2    bizitobs_l2c/H/long  moirai_small               99.568849   \n",
       "3      m4_weekly/W/short  moirai_small           320634.706664   \n",
       "\n",
       "   eval_metrics/MSE[0.5]  eval_metrics/MAE[0.5]  eval_metrics/MASE[0.5]   \n",
       "0              67.850121               5.013020                0.502710  \\\n",
       "1              73.605469               5.040342                0.508575   \n",
       "2              99.568849               5.755020                0.610783   \n",
       "3          320634.706664             278.256482                2.123471   \n",
       "\n",
       "   eval_metrics/MAPE[0.5]  eval_metrics/sMAPE[0.5]  eval_metrics/MSIS   \n",
       "0                0.478462                 0.636955           7.536384  \\\n",
       "1                0.561661                 0.795054          10.486613   \n",
       "2                0.712003                 0.807344          15.002673   \n",
       "3                0.067205                 0.068345          14.761419   \n",
       "\n",
       "   eval_metrics/RMSE[mean]  eval_metrics/NRMSE[mean]  eval_metrics/ND[0.5]   \n",
       "0                 8.237118                  0.444002              0.270215  \\\n",
       "1                 8.579363                  0.519493              0.305200   \n",
       "2                 9.978419                  0.609511              0.351533   \n",
       "3               566.246154                  0.103161              0.050694   \n",
       "\n",
       "   eval_metrics/mean_weighted_sum_quantile_loss        domain  num_variates  \n",
       "0                                      0.234670  Web/CloudOps             7  \n",
       "1                                      0.273815  Web/CloudOps             7  \n",
       "2                                      0.321291  Web/CloudOps             7  \n",
       "3                                      0.040013      Econ/Fin             1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../results/moirai_small/all_results.csv\")\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gift_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
